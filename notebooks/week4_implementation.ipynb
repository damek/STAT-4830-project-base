{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 Implementation: Circle Packing Baseline\n",
    "\n",
    "Goal: build a reproducible, no-RL baseline for a verifiable optimization loop (generate -> verify -> select -> refine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Problem Setup\n",
    "We pack `N` equal circles of radius `r` inside a unit square, enforcing strict validity constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "\n",
    "SEED = 7\n",
    "random.seed(SEED)\n",
    "\n",
    "N_CIRCLES = 18\n",
    "RADIUS = 0.08\n",
    "BOX_MIN, BOX_MAX = 0.0, 1.0\n",
    "\n",
    "ITERATIONS = 80\n",
    "POOL_SIZE = 64\n",
    "TOP_K = 8\n",
    "MUTATION_STD = 0.04\n",
    "\n",
    "print({\n",
    "    'seed': SEED,\n",
    "    'n_circles': N_CIRCLES,\n",
    "    'radius': RADIUS,\n",
    "    'iterations': ITERATIONS,\n",
    "    'pool_size': POOL_SIZE,\n",
    "    'top_k': TOP_K,\n",
    "    'mutation_std': MUTATION_STD,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Verifier and Objective\n",
    "Validity constraints: boundary + non-overlap.\n",
    "\n",
    "Score (higher is better):\n",
    "- `-1e6` for invalid candidates (hard rejection)\n",
    "- for valid candidates, maximize average pairwise center distance (proxy diversity/spread metric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EvalResult:\n",
    "    valid: bool\n",
    "    score: float\n",
    "    boundary_violations: int\n",
    "    overlap_violations: int\n",
    "\n",
    "def pairwise_dist(p, q):\n",
    "    return math.sqrt((p[0] - q[0]) ** 2 + (p[1] - q[1]) ** 2)\n",
    "\n",
    "def evaluate_candidate(centers, radius):\n",
    "    boundary_violations = 0\n",
    "    overlap_violations = 0\n",
    "\n",
    "    for x, y in centers:\n",
    "        if x < BOX_MIN + radius or x > BOX_MAX - radius:\n",
    "            boundary_violations += 1\n",
    "        if y < BOX_MIN + radius or y > BOX_MAX - radius:\n",
    "            boundary_violations += 1\n",
    "\n",
    "    min_sep = 2.0 * radius\n",
    "    for i in range(len(centers)):\n",
    "        for j in range(i + 1, len(centers)):\n",
    "            if pairwise_dist(centers[i], centers[j]) < min_sep:\n",
    "                overlap_violations += 1\n",
    "\n",
    "    valid = (boundary_violations == 0 and overlap_violations == 0)\n",
    "\n",
    "    if not valid:\n",
    "        return EvalResult(False, -1e6, boundary_violations, overlap_violations)\n",
    "\n",
    "    if len(centers) < 2:\n",
    "        spread = 0.0\n",
    "    else:\n",
    "        dsum = 0.0\n",
    "        count = 0\n",
    "        for i in range(len(centers)):\n",
    "            for j in range(i + 1, len(centers)):\n",
    "                dsum += pairwise_dist(centers[i], centers[j])\n",
    "                count += 1\n",
    "        spread = dsum / count\n",
    "\n",
    "    return EvalResult(True, spread, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Candidate Generation and Refinement\n",
    "Start from random candidates, then mutate top performers." 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_candidate(n):\n",
    "    return [\n",
    "        (random.uniform(BOX_MIN, BOX_MAX), random.uniform(BOX_MIN, BOX_MAX))\n",
    "        for _ in range(n)\n",
    "    ]\n",
    "\n",
    "def mutate_candidate(centers, std=MUTATION_STD):\n",
    "    mutated = []\n",
    "    for x, y in centers:\n",
    "        nx = x + random.gauss(0.0, std)\n",
    "        ny = y + random.gauss(0.0, std)\n",
    "        # Keep points in box; verifier still enforces strict boundary with radius.\n",
    "        nx = min(max(nx, BOX_MIN), BOX_MAX)\n",
    "        ny = min(max(ny, BOX_MIN), BOX_MAX)\n",
    "        mutated.append((nx, ny))\n",
    "    return mutated\n",
    "\n",
    "def build_pool(elites, pool_size, n):\n",
    "    pool = []\n",
    "    if not elites:\n",
    "        for _ in range(pool_size):\n",
    "            pool.append(random_candidate(n))\n",
    "        return pool\n",
    "\n",
    "    for _ in range(pool_size):\n",
    "        if random.random() < 0.25:\n",
    "            pool.append(random_candidate(n))\n",
    "        else:\n",
    "            base = random.choice(elites)\n",
    "            pool.append(mutate_candidate(base))\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Optimization Loop\n",
    "Tracks best-so-far score, valid rate, and violations." 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "best_candidate = None\n",
    "best_result = EvalResult(False, -1e9, 0, 0)\n",
    "elites = []\n",
    "\n",
    "start = time.time()\n",
    "for t in range(ITERATIONS):\n",
    "    pool = build_pool(elites, POOL_SIZE, N_CIRCLES)\n",
    "    scored = []\n",
    "\n",
    "    valid_count = 0\n",
    "    boundary_v = 0\n",
    "    overlap_v = 0\n",
    "\n",
    "    for cand in pool:\n",
    "        result = evaluate_candidate(cand, RADIUS)\n",
    "        scored.append((result.score, cand, result))\n",
    "        if result.valid:\n",
    "            valid_count += 1\n",
    "        boundary_v += result.boundary_violations\n",
    "        overlap_v += result.overlap_violations\n",
    "\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    top_items = scored[:TOP_K]\n",
    "    elites = [item[1] for item in top_items]\n",
    "\n",
    "    top_score, top_cand, top_eval = top_items[0]\n",
    "    if top_score > best_result.score:\n",
    "        best_result = top_eval\n",
    "        best_candidate = top_cand\n",
    "\n",
    "    history.append({\n",
    "        'iter': t,\n",
    "        'best_score_this_iter': top_score,\n",
    "        'best_score_so_far': best_result.score,\n",
    "        'valid_rate': valid_count / POOL_SIZE,\n",
    "        'boundary_violations': boundary_v,\n",
    "        'overlap_violations': overlap_v,\n",
    "    })\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print('done in seconds:', round(elapsed, 3))\n",
    "print('best valid:', best_result.valid)\n",
    "print('best score:', round(best_result.score, 6))\n",
    "print('final valid rate:', round(history[-1]['valid_rate'], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Basic Results and Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in history[:5]:\n",
    "    print(row)\n",
    "print('...')\n",
    "for row in history[-5:]:\n",
    "    print(row)\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    xs = [h['iter'] for h in history]\n",
    "    ys_best = [h['best_score_so_far'] for h in history]\n",
    "    ys_valid = [h['valid_rate'] for h in history]\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 4))\n",
    "    ax1.plot(xs, ys_best, label='best score so far')\n",
    "    ax1.set_xlabel('iteration')\n",
    "    ax1.set_ylabel('score')\n",
    "    ax1.legend(loc='upper left')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(xs, ys_valid, color='tab:orange', alpha=0.7, label='valid rate')\n",
    "    ax2.set_ylabel('valid rate')\n",
    "    ax2.legend(loc='upper right')\n",
    "\n",
    "    plt.title('Week 4 Baseline Diagnostics')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as exc:\n",
    "    print('matplotlib unavailable or plotting failed:', exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Week 4 Checklist\n",
    "Fill these after running:\n",
    "- Best score achieved\n",
    "- Whether best candidate is valid\n",
    "- Iteration where best score first appeared\n",
    "- Average valid rate\n",
    "- One failure mode and one fix for next week\n",
    "\n",
    "Planned extension: replace fixed mutate/refine policy with RL-style adaptation and compare sample efficiency under equal compute budget."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
